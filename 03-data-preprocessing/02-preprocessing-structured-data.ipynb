{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Structured Data\n",
    "\n",
    "Before we actually feed the data into any deep learning system we should look through it carefully. In addition to the kinds of big-picture problems that might arise in collecting data from a noisy world, we need to look out for missing values, strange outliers, and potential errors in the data. The data doesn't have to be completely error free, although obviously that would be best. Frequently, with the size of data we're dealing with, it is not realistic to completely scrub the data of any errors. \n",
    "\n",
    "Once we have a collection of data that has a tolerable amount of errors (ideally error free, though that does not HAVE to be the case) we have to transform it into a deep learning friendly format. There are a number of tricks that machine learning practitioners apply to get better results from the same data.\n",
    "\n",
    "It's also wise to explore the data and look for interesting outliers, correlation between different parts of the data, and other anomolies, oddities, and trends. Of course, we're hoping that our deep learning system can tease these out even better than we could—but that's not a good reason to shirk your own responsibility to understand the dataset. Sophisticated as they are, neural nets are still just tools, and understanding the data can help use hone our tools in the areas where they'll be most successful. \n",
    "\n",
    "For this lab we're going to use a public domain dataset from Kaggle. You can find the dataset here:\n",
    "\n",
    "https://www.kaggle.com/new-york-city/nyc-property-sales\n",
    "\n",
    "To run this code you'll need to download and unzip that data.\n",
    "\n",
    "There is useful supporting information about this dataset as well at the following two URLs:\n",
    "\n",
    "https://www1.nyc.gov/assets/finance/downloads/pdf/07pdf/glossary_rsf071607.pdf\n",
    "\n",
    "https://www1.nyc.gov/assets/finance/jump/hlpbldgcode.html\n",
    "\n",
    "The dataset is a record of every building/condo/appartment that was sold in New York City over a 12 month period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>NEIGHBORHOOD</th>\n",
       "      <th>BUILDING CLASS CATEGORY</th>\n",
       "      <th>TAX CLASS AT PRESENT</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>LOT</th>\n",
       "      <th>EASE-MENT</th>\n",
       "      <th>BUILDING CLASS AT PRESENT</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>...</th>\n",
       "      <th>RESIDENTIAL UNITS</th>\n",
       "      <th>COMMERCIAL UNITS</th>\n",
       "      <th>TOTAL UNITS</th>\n",
       "      <th>LAND SQUARE FEET</th>\n",
       "      <th>GROSS SQUARE FEET</th>\n",
       "      <th>YEAR BUILT</th>\n",
       "      <th>TAX CLASS AT TIME OF SALE</th>\n",
       "      <th>BUILDING CLASS AT TIME OF SALE</th>\n",
       "      <th>SALE PRICE</th>\n",
       "      <th>SALE DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2A</td>\n",
       "      <td>392</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>C2</td>\n",
       "      <td>153 AVENUE B</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1633</td>\n",
       "      <td>6440</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C2</td>\n",
       "      <td>6625000</td>\n",
       "      <td>2017-07-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td>26</td>\n",
       "      <td></td>\n",
       "      <td>C7</td>\n",
       "      <td>234 EAST 4TH   STREET</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>4616</td>\n",
       "      <td>18690</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C7</td>\n",
       "      <td>-</td>\n",
       "      <td>2016-12-14 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td>39</td>\n",
       "      <td></td>\n",
       "      <td>C7</td>\n",
       "      <td>197 EAST 3RD   STREET</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2212</td>\n",
       "      <td>7803</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C7</td>\n",
       "      <td>-</td>\n",
       "      <td>2016-12-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2B</td>\n",
       "      <td>402</td>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "      <td>C4</td>\n",
       "      <td>154 EAST 7TH STREET</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2272</td>\n",
       "      <td>6794</td>\n",
       "      <td>1913</td>\n",
       "      <td>2</td>\n",
       "      <td>C4</td>\n",
       "      <td>3936272</td>\n",
       "      <td>2016-09-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2A</td>\n",
       "      <td>404</td>\n",
       "      <td>55</td>\n",
       "      <td></td>\n",
       "      <td>C2</td>\n",
       "      <td>301 EAST 10TH   STREET</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2369</td>\n",
       "      <td>4615</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C2</td>\n",
       "      <td>8000000</td>\n",
       "      <td>2016-11-17 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  BOROUGH   NEIGHBORHOOD  \\\n",
       "0           4        1  ALPHABET CITY   \n",
       "1           5        1  ALPHABET CITY   \n",
       "2           6        1  ALPHABET CITY   \n",
       "3           7        1  ALPHABET CITY   \n",
       "4           8        1  ALPHABET CITY   \n",
       "\n",
       "                       BUILDING CLASS CATEGORY TAX CLASS AT PRESENT  BLOCK  \\\n",
       "0  07 RENTALS - WALKUP APARTMENTS                                2A    392   \n",
       "1  07 RENTALS - WALKUP APARTMENTS                                 2    399   \n",
       "2  07 RENTALS - WALKUP APARTMENTS                                 2    399   \n",
       "3  07 RENTALS - WALKUP APARTMENTS                                2B    402   \n",
       "4  07 RENTALS - WALKUP APARTMENTS                                2A    404   \n",
       "\n",
       "   LOT EASE-MENT BUILDING CLASS AT PRESENT                 ADDRESS  ...  \\\n",
       "0    6                                  C2            153 AVENUE B  ...   \n",
       "1   26                                  C7   234 EAST 4TH   STREET  ...   \n",
       "2   39                                  C7   197 EAST 3RD   STREET  ...   \n",
       "3   21                                  C4     154 EAST 7TH STREET  ...   \n",
       "4   55                                  C2  301 EAST 10TH   STREET  ...   \n",
       "\n",
       "  RESIDENTIAL UNITS  COMMERCIAL UNITS  TOTAL UNITS  LAND SQUARE FEET  \\\n",
       "0                 5                 0            5              1633   \n",
       "1                28                 3           31              4616   \n",
       "2                16                 1           17              2212   \n",
       "3                10                 0           10              2272   \n",
       "4                 6                 0            6              2369   \n",
       "\n",
       "   GROSS SQUARE FEET YEAR BUILT TAX CLASS AT TIME OF SALE  \\\n",
       "0               6440       1900                         2   \n",
       "1              18690       1900                         2   \n",
       "2               7803       1900                         2   \n",
       "3               6794       1913                         2   \n",
       "4               4615       1900                         2   \n",
       "\n",
       "   BUILDING CLASS AT TIME OF SALE  SALE PRICE            SALE DATE  \n",
       "0                              C2     6625000  2017-07-19 00:00:00  \n",
       "1                              C7         -    2016-12-14 00:00:00  \n",
       "2                              C7         -    2016-12-09 00:00:00  \n",
       "3                              C4     3936272  2016-09-23 00:00:00  \n",
       "4                              C2     8000000  2016-11-17 00:00:00  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas is a fantastic and powerful tool for working with structured data\n",
    "# it's the best of spreadsheets + python, and it has quickly become a go to\n",
    "# library for data scientists in python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your path may vary, change this appropriately\n",
    "path_to_ny_sales = 'datasets/nyc-rolling-sales.csv'\n",
    "\n",
    "# One of the things we love about pandas is that it's easy to load CSV data\n",
    "# into a \"data frame\"\n",
    "sales_df = pd.read_csv(path_to_ny_sales)\n",
    "\n",
    "# And, it makes it easy to take a look at the first n items:\n",
    "sales_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>LOT</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>RESIDENTIAL UNITS</th>\n",
       "      <th>COMMERCIAL UNITS</th>\n",
       "      <th>TOTAL UNITS</th>\n",
       "      <th>YEAR BUILT</th>\n",
       "      <th>TAX CLASS AT TIME OF SALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84548.000000</td>\n",
       "      <td>84548.000000</td>\n",
       "      <td>84548.000000</td>\n",
       "      <td>84548.000000</td>\n",
       "      <td>84548.000000</td>\n",
       "      <td>84548.000000</td>\n",
       "      <td>84548.000000</td>\n",
       "      <td>84548.000000</td>\n",
       "      <td>84548.000000</td>\n",
       "      <td>84548.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10344.359878</td>\n",
       "      <td>2.998758</td>\n",
       "      <td>4237.218976</td>\n",
       "      <td>376.224015</td>\n",
       "      <td>10731.991614</td>\n",
       "      <td>2.025264</td>\n",
       "      <td>0.193559</td>\n",
       "      <td>2.249184</td>\n",
       "      <td>1789.322976</td>\n",
       "      <td>1.657485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7151.779436</td>\n",
       "      <td>1.289790</td>\n",
       "      <td>3568.263407</td>\n",
       "      <td>658.136814</td>\n",
       "      <td>1290.879147</td>\n",
       "      <td>16.721037</td>\n",
       "      <td>8.713183</td>\n",
       "      <td>18.972584</td>\n",
       "      <td>537.344993</td>\n",
       "      <td>0.819341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4231.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1322.750000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>10305.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8942.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3311.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>11209.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15987.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6281.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>11357.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26739.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16322.000000</td>\n",
       "      <td>9106.000000</td>\n",
       "      <td>11694.000000</td>\n",
       "      <td>1844.000000</td>\n",
       "      <td>2261.000000</td>\n",
       "      <td>2261.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0       BOROUGH         BLOCK           LOT      ZIP CODE  \\\n",
       "count  84548.000000  84548.000000  84548.000000  84548.000000  84548.000000   \n",
       "mean   10344.359878      2.998758   4237.218976    376.224015  10731.991614   \n",
       "std     7151.779436      1.289790   3568.263407    658.136814   1290.879147   \n",
       "min        4.000000      1.000000      1.000000      1.000000      0.000000   \n",
       "25%     4231.000000      2.000000   1322.750000     22.000000  10305.000000   \n",
       "50%     8942.000000      3.000000   3311.000000     50.000000  11209.000000   \n",
       "75%    15987.250000      4.000000   6281.000000   1001.000000  11357.000000   \n",
       "max    26739.000000      5.000000  16322.000000   9106.000000  11694.000000   \n",
       "\n",
       "       RESIDENTIAL UNITS  COMMERCIAL UNITS   TOTAL UNITS    YEAR BUILT  \\\n",
       "count       84548.000000      84548.000000  84548.000000  84548.000000   \n",
       "mean            2.025264          0.193559      2.249184   1789.322976   \n",
       "std            16.721037          8.713183     18.972584    537.344993   \n",
       "min             0.000000          0.000000      0.000000      0.000000   \n",
       "25%             0.000000          0.000000      1.000000   1920.000000   \n",
       "50%             1.000000          0.000000      1.000000   1940.000000   \n",
       "75%             2.000000          0.000000      2.000000   1965.000000   \n",
       "max          1844.000000       2261.000000   2261.000000   2017.000000   \n",
       "\n",
       "       TAX CLASS AT TIME OF SALE  \n",
       "count               84548.000000  \n",
       "mean                    1.657485  \n",
       "std                     0.819341  \n",
       "min                     1.000000  \n",
       "25%                     1.000000  \n",
       "50%                     2.000000  \n",
       "75%                     2.000000  \n",
       "max                     4.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And a summary with bundles of useful information on the numerical fields\n",
    "sales_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing unwanted columns\n",
    "\n",
    "We won't always want every piece of data do be considered by our model. Lets delete some columns, and discuss why these might be good candidates for deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>NEIGHBORHOOD</th>\n",
       "      <th>BUILDING CLASS CATEGORY</th>\n",
       "      <th>TAX CLASS AT PRESENT</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>EASE-MENT</th>\n",
       "      <th>BUILDING CLASS AT PRESENT</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>RESIDENTIAL UNITS</th>\n",
       "      <th>COMMERCIAL UNITS</th>\n",
       "      <th>TOTAL UNITS</th>\n",
       "      <th>LAND SQUARE FEET</th>\n",
       "      <th>GROSS SQUARE FEET</th>\n",
       "      <th>YEAR BUILT</th>\n",
       "      <th>TAX CLASS AT TIME OF SALE</th>\n",
       "      <th>BUILDING CLASS AT TIME OF SALE</th>\n",
       "      <th>SALE PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2A</td>\n",
       "      <td>392</td>\n",
       "      <td></td>\n",
       "      <td>C2</td>\n",
       "      <td>10009</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1633</td>\n",
       "      <td>6440</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C2</td>\n",
       "      <td>6625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td></td>\n",
       "      <td>C7</td>\n",
       "      <td>10009</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>4616</td>\n",
       "      <td>18690</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C7</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2</td>\n",
       "      <td>399</td>\n",
       "      <td></td>\n",
       "      <td>C7</td>\n",
       "      <td>10009</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2212</td>\n",
       "      <td>7803</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C7</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2B</td>\n",
       "      <td>402</td>\n",
       "      <td></td>\n",
       "      <td>C4</td>\n",
       "      <td>10009</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2272</td>\n",
       "      <td>6794</td>\n",
       "      <td>1913</td>\n",
       "      <td>2</td>\n",
       "      <td>C4</td>\n",
       "      <td>3936272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ALPHABET CITY</td>\n",
       "      <td>07 RENTALS - WALKUP APARTMENTS</td>\n",
       "      <td>2A</td>\n",
       "      <td>404</td>\n",
       "      <td></td>\n",
       "      <td>C2</td>\n",
       "      <td>10009</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2369</td>\n",
       "      <td>4615</td>\n",
       "      <td>1900</td>\n",
       "      <td>2</td>\n",
       "      <td>C2</td>\n",
       "      <td>8000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BOROUGH   NEIGHBORHOOD                      BUILDING CLASS CATEGORY  \\\n",
       "0        1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "1        1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "2        1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "3        1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "4        1  ALPHABET CITY  07 RENTALS - WALKUP APARTMENTS                \n",
       "\n",
       "  TAX CLASS AT PRESENT  BLOCK EASE-MENT BUILDING CLASS AT PRESENT  ZIP CODE  \\\n",
       "0                   2A    392                                  C2     10009   \n",
       "1                    2    399                                  C7     10009   \n",
       "2                    2    399                                  C7     10009   \n",
       "3                   2B    402                                  C4     10009   \n",
       "4                   2A    404                                  C2     10009   \n",
       "\n",
       "   RESIDENTIAL UNITS  COMMERCIAL UNITS  TOTAL UNITS LAND SQUARE FEET  \\\n",
       "0                  5                 0            5             1633   \n",
       "1                 28                 3           31             4616   \n",
       "2                 16                 1           17             2212   \n",
       "3                 10                 0           10             2272   \n",
       "4                  6                 0            6             2369   \n",
       "\n",
       "  GROSS SQUARE FEET  YEAR BUILT  TAX CLASS AT TIME OF SALE  \\\n",
       "0              6440        1900                          2   \n",
       "1             18690        1900                          2   \n",
       "2              7803        1900                          2   \n",
       "3              6794        1913                          2   \n",
       "4              4615        1900                          2   \n",
       "\n",
       "  BUILDING CLASS AT TIME OF SALE SALE PRICE  \n",
       "0                             C2    6625000  \n",
       "1                             C7        -    \n",
       "2                             C7        -    \n",
       "3                             C4    3936272  \n",
       "4                             C2    8000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df = sales_df.drop(columns=[\n",
    "    'Unnamed: 0',\n",
    "    'ADDRESS',          # Hard to parse. Block/zip/borough/neighborhood capture all the value we need. \n",
    "    'APARTMENT NUMBER', # Likely irrelevent to the price. Ought to be categorical, which would make data large.\n",
    "    'SALE DATE',        # Everything was within a 12 month period, likely irrelevant and hard to parse.\n",
    "    'LOT'               # A lot is a unique identifier within a block, and categorical. Not worth it. \n",
    "])\n",
    "\n",
    "# Look again with dropped columns\n",
    "sales_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing erronious datatypes\n",
    "\n",
    "For a variety of reasons, sometimes the data won't have the datatype we expect when we import it and we'll have to take some corrective measures.\n",
    "\n",
    "### Micro-exercise: Identify Some Wrongness\n",
    "\n",
    "Look at the following list of columns and their datatypes. Which of these stand out as potentially erronious? Form a hypthesis about why they might be exhibiting this wrong type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOROUGH int64\n",
      "NEIGHBORHOOD object\n",
      "BUILDING CLASS CATEGORY object\n",
      "TAX CLASS AT PRESENT object\n",
      "BLOCK int64\n",
      "EASE-MENT object\n",
      "BUILDING CLASS AT PRESENT object\n",
      "ZIP CODE int64\n",
      "RESIDENTIAL UNITS int64\n",
      "COMMERCIAL UNITS int64\n",
      "TOTAL UNITS int64\n",
      "LAND SQUARE FEET object\n",
      "GROSS SQUARE FEET object\n",
      "YEAR BUILT int64\n",
      "TAX CLASS AT TIME OF SALE int64\n",
      "BUILDING CLASS AT TIME OF SALE object\n",
      "SALE PRICE object\n"
     ]
    }
   ],
   "source": [
    "# Sometimes we get some unexpected datatypes when loading data\n",
    "for col, dtype in zip(sales_df.columns, sales_df.dtypes):\n",
    "    print(col, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of our data that appears numeric really shouldn't be... instead lets treat them as categorical columns.\n",
    "categorical_columns = [\n",
    "    'BOROUGH',\n",
    "    'BLOCK',\n",
    "    'ZIP CODE',\n",
    "    'TAX CLASS AT TIME OF SALE'\n",
    "]\n",
    "\n",
    "for c in categorical_columns:\n",
    "    sales_df[c] = sales_df[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         6625000\n",
       "1             -  \n",
       "2             -  \n",
       "3         3936272\n",
       "4         8000000\n",
       "           ...   \n",
       "84543      450000\n",
       "84544      550000\n",
       "84545      460000\n",
       "84546    11693337\n",
       "84547       69300\n",
       "Name: SALE PRICE, Length: 84548, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at the sale price and see if we can understand why it's not a numeric type...\n",
    "sales_df['SALE PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' -  '], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks like the data is a string type, and sometimes has a value of -\n",
    "# The documentation suggests the - value means that there was no sale\n",
    "# just a property transfer for nothing, such as an inheritance. \n",
    "\n",
    "# The following operations to obtain \"coerced_sales\" are only meant\n",
    "# to evaluate the data. \n",
    "\n",
    "# Lets try to coerce the data to numeric where possible:\n",
    "# coerce \"sales_df['SALE PRICE']\" and store it into \"coerced_sales\".\n",
    "coerced_sales = pd.to_numeric(sales_df['SALE PRICE'], errors='coerce')\n",
    "\n",
    "# Values that cannot be coerced are changed to Not a Number (NaN). \n",
    "# We can use this code to examine those values:\n",
    "# get only the \"sales_df['SALE PRICE']\" values where \"coerced_sales.isna()\"\n",
    "# is positive. \n",
    "only_non_numerics = sales_df['SALE PRICE'][coerced_sales.isna()]\n",
    "\n",
    "# And this to print all the unique values from only_non_numerics\n",
    "only_non_numerics.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, indeed, the only value that wasn't a number as a string was the ' - ' value. \n",
    "# good to know. Lets go ahead and coerce them all to zero.\n",
    "\n",
    "# Coerce the data to numeric where possible repeating the same coercion operation\n",
    "# as above, but this time on the dataset we need to operate on. \n",
    "sales_df['SALE PRICE'] = pd.to_numeric(sales_df['SALE PRICE'], errors='coerce')\n",
    "sales_df['SALE PRICE'] = sales_df['SALE PRICE'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESIDENTIAL UNITS</th>\n",
       "      <th>COMMERCIAL UNITS</th>\n",
       "      <th>TOTAL UNITS</th>\n",
       "      <th>YEAR BUILT</th>\n",
       "      <th>SALE PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84548.000000</td>\n",
       "      <td>84548.000000</td>\n",
       "      <td>84548.000000</td>\n",
       "      <td>84548.000000</td>\n",
       "      <td>8.454800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.025264</td>\n",
       "      <td>0.193559</td>\n",
       "      <td>2.249184</td>\n",
       "      <td>1789.322976</td>\n",
       "      <td>1.056623e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.721037</td>\n",
       "      <td>8.713183</td>\n",
       "      <td>18.972584</td>\n",
       "      <td>537.344993</td>\n",
       "      <td>1.038794e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1940.000000</td>\n",
       "      <td>4.150000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>8.300000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1844.000000</td>\n",
       "      <td>2261.000000</td>\n",
       "      <td>2261.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2.210000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RESIDENTIAL UNITS  COMMERCIAL UNITS   TOTAL UNITS    YEAR BUILT  \\\n",
       "count       84548.000000      84548.000000  84548.000000  84548.000000   \n",
       "mean            2.025264          0.193559      2.249184   1789.322976   \n",
       "std            16.721037          8.713183     18.972584    537.344993   \n",
       "min             0.000000          0.000000      0.000000      0.000000   \n",
       "25%             0.000000          0.000000      1.000000   1920.000000   \n",
       "50%             1.000000          0.000000      1.000000   1940.000000   \n",
       "75%             2.000000          0.000000      2.000000   1965.000000   \n",
       "max          1844.000000       2261.000000   2261.000000   2017.000000   \n",
       "\n",
       "         SALE PRICE  \n",
       "count  8.454800e+04  \n",
       "mean   1.056623e+06  \n",
       "std    1.038794e+07  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    4.150000e+05  \n",
       "75%    8.300000e+05  \n",
       "max    2.210000e+09  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro-exercise: Dropping missing data instead\n",
    "\n",
    "The following code demonstrates that the land and gross square feet columns also have missing values. \n",
    "\n",
    "Using the documentation here: [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) write some code that drops all the rows where `LAND SQUARE FEET` has a missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAND SQUARE FEET [' -  ']\n",
      "GROSS SQUARE FEET [' -  ']\n"
     ]
    }
   ],
   "source": [
    "# Two other columns should be numeric, but are objects. Lets look at them too to prove they have missing values:\n",
    "convert_to_numeric = [\n",
    "    'LAND SQUARE FEET',\n",
    "    'GROSS SQUARE FEET'\n",
    "]\n",
    "\n",
    "for col in convert_to_numeric:\n",
    "    coerced = pd.to_numeric(sales_df[col], errors='coerce')\n",
    "    only_non_numerics = sales_df[col][coerced.isna()]\n",
    "\n",
    "    # And this to print all the unique values from only_non_numerics\n",
    "    print(col, only_non_numerics.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESIDENTIAL UNITS</th>\n",
       "      <th>COMMERCIAL UNITS</th>\n",
       "      <th>TOTAL UNITS</th>\n",
       "      <th>LAND SQUARE FEET</th>\n",
       "      <th>YEAR BUILT</th>\n",
       "      <th>SALE PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58296.000000</td>\n",
       "      <td>58296.000000</td>\n",
       "      <td>58296.000000</td>\n",
       "      <td>5.829600e+04</td>\n",
       "      <td>58296.000000</td>\n",
       "      <td>5.829600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.742813</td>\n",
       "      <td>0.279796</td>\n",
       "      <td>3.038167</td>\n",
       "      <td>3.941676e+03</td>\n",
       "      <td>1812.902360</td>\n",
       "      <td>9.817507e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.089271</td>\n",
       "      <td>10.492071</td>\n",
       "      <td>22.798842</td>\n",
       "      <td>4.198397e+04</td>\n",
       "      <td>490.972213</td>\n",
       "      <td>1.226303e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.650000e+03</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.325000e+03</td>\n",
       "      <td>1931.000000</td>\n",
       "      <td>3.780000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.500000e+03</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>7.400000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1844.000000</td>\n",
       "      <td>2261.000000</td>\n",
       "      <td>2261.000000</td>\n",
       "      <td>4.252327e+06</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2.210000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RESIDENTIAL UNITS  COMMERCIAL UNITS   TOTAL UNITS  LAND SQUARE FEET  \\\n",
       "count       58296.000000      58296.000000  58296.000000      5.829600e+04   \n",
       "mean            2.742813          0.279796      3.038167      3.941676e+03   \n",
       "std            20.089271         10.492071     22.798842      4.198397e+04   \n",
       "min             0.000000          0.000000      0.000000      0.000000e+00   \n",
       "25%             1.000000          0.000000      1.000000      1.650000e+03   \n",
       "50%             1.000000          0.000000      1.000000      2.325000e+03   \n",
       "75%             2.000000          0.000000      2.000000      3.500000e+03   \n",
       "max          1844.000000       2261.000000   2261.000000      4.252327e+06   \n",
       "\n",
       "         YEAR BUILT    SALE PRICE  \n",
       "count  58296.000000  5.829600e+04  \n",
       "mean    1812.902360  9.817507e+05  \n",
       "std      490.972213  1.226303e+07  \n",
       "min        0.000000  0.000000e+00  \n",
       "25%     1920.000000  0.000000e+00  \n",
       "50%     1931.000000  3.780000e+05  \n",
       "75%     1960.000000  7.400000e+05  \n",
       "max     2017.000000  2.210000e+09  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code to drop rows here.\n",
    "sales_df['LAND SQUARE FEET'] = pd.to_numeric(sales_df['LAND SQUARE FEET'], errors='coerce')\n",
    "\n",
    "# IMPORTANT\n",
    "# Pay attention at the return type. \n",
    "# dataframe.dropna() returns a DataFrame with NA entries \n",
    "# dropped from it, so we have to store the result in a variable.\n",
    "sales_df = sales_df.dropna(subset=['LAND SQUARE FEET'])\n",
    "\n",
    "sales_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESIDENTIAL UNITS</th>\n",
       "      <th>COMMERCIAL UNITS</th>\n",
       "      <th>TOTAL UNITS</th>\n",
       "      <th>LAND SQUARE FEET</th>\n",
       "      <th>YEAR BUILT</th>\n",
       "      <th>SALE PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56930.000000</td>\n",
       "      <td>56930.000000</td>\n",
       "      <td>56930.000000</td>\n",
       "      <td>5.693000e+04</td>\n",
       "      <td>56930.000000</td>\n",
       "      <td>5.693000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.769015</td>\n",
       "      <td>0.270314</td>\n",
       "      <td>3.055261</td>\n",
       "      <td>4.042317e+03</td>\n",
       "      <td>1845.510434</td>\n",
       "      <td>9.773214e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.031627</td>\n",
       "      <td>10.318468</td>\n",
       "      <td>22.672327</td>\n",
       "      <td>3.503270e+04</td>\n",
       "      <td>429.969853</td>\n",
       "      <td>1.234363e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.045250e+03</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.680000e+03</td>\n",
       "      <td>1931.000000</td>\n",
       "      <td>3.877105e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.560000e+03</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>7.490000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1844.000000</td>\n",
       "      <td>2261.000000</td>\n",
       "      <td>2261.000000</td>\n",
       "      <td>3.750565e+06</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2.210000e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RESIDENTIAL UNITS  COMMERCIAL UNITS   TOTAL UNITS  LAND SQUARE FEET  \\\n",
       "count       56930.000000      56930.000000  56930.000000      5.693000e+04   \n",
       "mean            2.769015          0.270314      3.055261      4.042317e+03   \n",
       "std            20.031627         10.318468     22.672327      3.503270e+04   \n",
       "min             0.000000          0.000000      0.000000      0.000000e+00   \n",
       "25%             1.000000          0.000000      1.000000      1.045250e+03   \n",
       "50%             1.000000          0.000000      1.000000      1.680000e+03   \n",
       "75%             2.000000          0.000000      2.000000      2.560000e+03   \n",
       "max          1844.000000       2261.000000   2261.000000      3.750565e+06   \n",
       "\n",
       "         YEAR BUILT    SALE PRICE  \n",
       "count  56930.000000  5.693000e+04  \n",
       "mean    1845.510434  9.773214e+05  \n",
       "std      429.969853  1.234363e+07  \n",
       "min        0.000000  0.000000e+00  \n",
       "25%     1920.000000  0.000000e+00  \n",
       "50%     1931.000000  3.877105e+05  \n",
       "75%     1960.000000  7.490000e+05  \n",
       "max     2017.000000  2.210000e+09  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert first, then drop rows where the value could not be converted to a number\n",
    "sales_df['LAND SQUARE FEET'] = pd.to_numeric(sales_df[col], errors='coerce')\n",
    "sales_df = sales_df.dropna(subset=['LAND SQUARE FEET'])\n",
    "\n",
    "# Note that land square feet now appears in the descriptive stats...\n",
    "sales_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Alternative for Missing Data: Imputation\n",
    "\n",
    "Sometimes, we'd rather not just throw out the data in the rest of the rows. If it seems appropriate, we can use a summary statistic like the mean or median in place of the missing values instead of throwing them away. However, use careful judgement when deciding to do this, it may not be appropriate in many contexts.\n",
    "\n",
    "In this example we'll impute missing values using the mean for the GROSS SQUARE FEET column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So... similarly there are missing values. But, unlike the sale data, we don't have \n",
    "# any clues about what this means, and it's hard to imagine that a building exists with\n",
    "# but occupies zero square feet... We'll apply another common tactic called \"imputation\"\n",
    "# We're just going to use the mean value when there is missing data, it's better than nothing\n",
    "# even though it may be wrong.\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "col = 'GROSS SQUARE FEET'\n",
    "\n",
    "coerced = pd.to_numeric(sales_df[col], errors='coerce')\n",
    "sales_df[col] = coerced\n",
    "sales_df[col] = sales_df[col].astype('float')\n",
    "    \n",
    "# Then, we can use the Imputer to fill in any missing values\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean') \n",
    "\n",
    "# Only fit it on our relevant column, then transform creates the data for the column with imputed values\n",
    "# the imputer generally works with 2D data, so we have to comply a bit which is why we have the additional\n",
    "# square brackets around sales_df[col]\n",
    "imputer.fit([sales_df[col]]) \n",
    "imputed_values = imputer.transform([sales_df[col]])\n",
    "\n",
    "# Now replace our old Series with the new imputed values. \n",
    "# This syntax is more or less coercing a row vector to a column vector.\n",
    "sales_df['GROSS SQUARE FEET'] = imputed_values[0] # Again, imputed values are 2D...\n",
    "\n",
    "sales_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring The Data a Bit\n",
    "\n",
    "Pandas and matplotlib play nice together, and we can easily make some useful charts and figures to help us understand out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A correlation matrix example:\n",
    "correlation_matrix = sales_df.corr()\n",
    "plt.matshow(correlation_matrix)\n",
    "plt.xticks(range(len(correlation_matrix.columns)), correlation_matrix.columns, rotation='vertical');\n",
    "plt.yticks(range(len(correlation_matrix.columns)), correlation_matrix.columns);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not surprising that total units seems to correlate most with price. \n",
    "# Interesting that residential units seems more correlated than commercial\n",
    "\n",
    "# What haven't we looked at...\n",
    "sales_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmm, we haven't see anything to do with ease-ment yet. Lets get a sample of what kind of values are in there.\n",
    "sales_df['EASE-MENT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It only has one value, junk it, it literally cannot be useful to an ML model if it always has the value ' '. \n",
    "sales_df = sales_df.drop(columns=['EASE-MENT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lets plot two interesting charts for any numeric column\n",
    "for col, dtype in zip(sales_df.columns, sales_df.dtypes):\n",
    "    if dtype not in ['float', 'int', 'float64', 'int64']: continue\n",
    "\n",
    "    print(col)\n",
    "    sales_df.boxplot(column=[col])\n",
    "    sales_df.hist(column=[col])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Outliers?\n",
    "\n",
    "Something to note about these charts is that, all of our numerical data seems to have a handful of extreme outliers. This might not be a challenge, because they are likely correlated. As in, the building with 1000+ units is probably also one of the sale price outliers. But it does sort of make the histograms unhelpful. \n",
    "\n",
    "We could consider pruning these outliers before going ahead with the rest of this data processing. Lets use some rough and tumble outlier detection code from Stack Overflow and replot.\n",
    "\n",
    "Depending on your goals, it might not make sense to keep the outliers, and because of their status as outliers it is often difficult to train a model to accurately predict this rare events. Often, it makes sense to drop outliers. Doing so in our case definitely makes these plots more useful and interesting too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Lets plot two interesting charts:\n",
    "for col, dtype in zip(sales_df.columns, sales_df.dtypes):\n",
    "    if dtype not in ['float', 'int', 'float64', 'int64']: continue\n",
    "\n",
    "    print(col)\n",
    "    \n",
    "    # Quick and dirty outlier filtering, anything over 2 std deviations from the mean \n",
    "    # filtered out. \n",
    "    filtered_col = sales_df[col][np.abs(stats.zscore(sales_df[col])) < 2]\n",
    "    \n",
    "    filtered_col.plot.box()\n",
    "    plt.show()\n",
    "    \n",
    "    filtered_col.hist(bins=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning vs Preparing\n",
    "\n",
    "What we've done above is mostly just cleaning the data. We looked for missing values, and did some spot/sanity checks on our data. We did one thing that you might consider preparing: making some columns categorical. In addition to make sure the data is clean and error free, it's common practice to prepare the data so that it plays nice with neural networks. Two common examples are centering the mean about 0, and normalize the range to be between (0 to 1) or (-1 to 1).\n",
    "\n",
    "Why? Consider this: year built, square feet, and total units are all going to impact the sale price. One of those might be more impactful than the other, but in the end our neural network is doing a bunch of complex addition and multiplication with those values, but year is always going to be in a range between basically 1900-2017, and units are almost always between 0-50 or so. 1900, when used as a multiplicitive scalar, is going to have a bigger impact than 50. \n",
    "\n",
    "For this, and other reasons, it's common to normalize the data so that every datapoint is reduced to it's place within the distribution and to center that distribution between -1 and 1 or 0 and 1. Lets normalize all our numeric values to be between 0 and 1. Note that there are other scaling choices we could make, see the reading resources for this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Note that we are NOT going to scale \"sale price\" because\n",
    "# ultimately that will be our target value. WE still need the\n",
    "# label to be in the format we wish to predict. \n",
    "cols_to_scale = [\n",
    "    'RESIDENTIAL UNITS',\n",
    "    'COMMERCIAL UNITS',\n",
    "    'TOTAL UNITS',\n",
    "    'LAND SQUARE FEET',\n",
    "    'GROSS SQUARE FEET',\n",
    "    'YEAR BUILT'\n",
    "]\n",
    "\n",
    "scaled_cols = scaler.fit_transform(sales_df[cols_to_scale])\n",
    "\n",
    "# Wow, was it really that easy? (no)\n",
    "scaled_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, we just got back an NDArray, and we need to put these\n",
    "# columns back into a dataframe.\n",
    "scaled_df = sales_df.copy(deep=True)\n",
    "\n",
    "for i, col  in enumerate(cols_to_scale):\n",
    "    scaled_df[col] = scaled_cols[:, i]\n",
    "\n",
    "scaled_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro-exercise: Standard Scaling\n",
    "\n",
    "Min/max scaling and standard scaling are a bit different. Min/max coerces the values into a range of 0-1 and keeps the data's distribution intact. Extracting the original value from the min/max'd value is simple. You store the original min and max values then use the formula `Xi = (Xi - Xmin)/(Xmax-Xmin)`\n",
    "\n",
    "Another common scaling method is called \"Standard Scaling\" which coerces the data into a normal distrubtion with its mean centered at 0 with standard deviation of 1.\n",
    "\n",
    "Using the above code as a guide and this documentation, apply a StandardScalar to this dataframe and then look at the describe results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Note that we are NOT going to scale \"sale price\" because\n",
    "# ultimately that will be our target value. WE still need the\n",
    "# label to be in the format we wish to predict. \n",
    "cols_to_scale = [\n",
    "    'RESIDENTIAL UNITS',\n",
    "    'COMMERCIAL UNITS',\n",
    "    'TOTAL UNITS',\n",
    "    'LAND SQUARE FEET',\n",
    "    'GROSS SQUARE FEET',\n",
    "    'YEAR BUILT'\n",
    "]\n",
    "\n",
    "scaled_cols = scaler.fit_transform(sales_df[cols_to_scale])\n",
    "\n",
    "# So, we just got back an NDArray, and we need to put these\n",
    "# columns back into a dataframe.\n",
    "scaled_df = sales_df.copy(deep=True)\n",
    "\n",
    "for i, col  in enumerate(cols_to_scale):\n",
    "    scaled_df[col] = scaled_cols[:, i]\n",
    "\n",
    "scaled_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding with get_dummies\n",
    "\n",
    "For categorical data, we most likely want to encode it with a one-hot encoding, which pandas makes easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even though we labeled some columns as \"category\" we still need to one-hot \n",
    "# encode them. Pandas makes this super easy too:\n",
    "scaled_dummy_df = pd.get_dummies(scaled_df)\n",
    "scaled_dummy_df.head(1)\n",
    "\n",
    "# Note that this takes awhile, it's procecssing a lot of data. \n",
    "# Note also that pandas automatically looks for columns with\n",
    "# a categorical type, so being explicit above was important \n",
    "# to making this part easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holy crap, 12,413 columns!\n",
    "\n",
    "# Note that all our numeric columns are between 0 and 1, except SALE PRICE\n",
    "# All that's left to do here is to separate the labels from the features.\n",
    "\n",
    "x_train = scaled_dummy_df.drop(columns=['SALE PRICE'])\n",
    "y_train = scaled_dummy_df['SALE PRICE']\n",
    "\n",
    "x_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Completeness, Lets Train a Model\n",
    "\n",
    "This model is dead stupid and fails catastrophically. It is very possible to do better with a more careful curation of the data and a better architecture, but it might or might not be possible to to excellent on this dataset... In the homework exercise you'll be asked to consider this more carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweet, lets make a simple neural net with keras to make sure we can run the data\n",
    "# through it. We don't expect great predictions out of this simple model we just\n",
    "# want to be sure that we can :\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Sigmoid and other functions that squash the output might not be\n",
    "# very appropriate for this task, because our target values are \n",
    "# quite large!\n",
    "model.add(Dense(units=32, activation='relu', input_shape=(len(x_train.columns),)))\n",
    "\n",
    "# For regression it's common to use a linear activation function\n",
    "# since our output could be anything. In our case, it would never\n",
    "# make sense to guess less than 0, so I'm using relu\n",
    "model.add(Dense(units=1, activation='relu'))\n",
    "\n",
    "# This function provides useful text data for our network\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE is pretty common for regression tasks\n",
    "model.compile(optimizer=\"adam\", loss='mean_squared_error')\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=5, verbose=True, validation_split=.2)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So... our model didn't do so great. Okay, it did terribly. \n",
    "# It's off by a lot and is clearly overfitting the training data.\n",
    "\n",
    "# Why might we be getting such poor performance? \n",
    "\n",
    "# How could we improve?\n",
    "\n",
    "# What should we do to the data?\n",
    "\n",
    "# What about to the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two things I would look at:\n",
    "\n",
    "# Consider discritizing and building a classifier instead of a regressor! \n",
    "  # Neural networks tend to be much better at classification tasks.\n",
    "  # Plus, it's just easier to predict 1 of 10 values compared to a \n",
    "  # continious space $0-$100,000,000 or so\n",
    "\n",
    "# Consider dropping the values with 0 SALE PRICE or any very low value\n",
    "  # those are not representative of actual sale prices!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
